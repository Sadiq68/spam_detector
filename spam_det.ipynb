{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "#from nb_model import NB_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "47462\n",
      "19670\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "hamwords = {}\n",
    "hamdoc_count = 0\n",
    "hamfiles = [file for file in glob.glob(\"./train/*ham*.txt\")]\n",
    "\n",
    "\n",
    "for file in hamfiles:\n",
    "    hamdoc_count  = hamdoc_count+1\n",
    "    doc = open(file, 'r').read().lower()\n",
    "    doc = re.sub('[a-z]*@*.com', '', doc)\n",
    "    doc = re.sub('[a-z]*-*.com', '', doc)\n",
    "    doc = re.sub('<*[a-z]*>', '', doc)\n",
    "    words = [word for word in re.split('[^a-zA-Z]',doc)]\n",
    "    for word in words:\n",
    "        if word != '' and word not in stopwords:\n",
    "            try:\n",
    "                hamwords[word] += 1\n",
    "            except KeyError:\n",
    "                hamwords[word] = 1\n",
    "\n",
    "spamdoc_count = 0\n",
    "spamwords = {}\n",
    "spamfiles = [file for file in glob.glob(\"./train/*spam*.txt\")]\n",
    "for file in spamfiles:\n",
    "    spamdoc_count = spamdoc_count+1\n",
    "    doc = open(file, 'r').read().lower()\n",
    "    words = [word for word in re.split('[^a-zA-Z]',doc)]\n",
    "    for word in words:\n",
    "        if word != '' and word not in stopwords:\n",
    "            try:\n",
    "                spamwords[word] += 1\n",
    "            except KeyError:\n",
    "                spamwords[word] = 1\n",
    "    \n",
    "print(len(vocab))\n",
    "print(len(spamwords))\n",
    "print(len(hamwords))\n",
    "\n",
    "#(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'will', 'one', 'your', 'get', 'was', 'what', 'they', 'just', 'so', 'has', 'out', 'v', 'p', 'about', 'thu', 'information', 'we', 'fri', 'sat', 'fork', 'lists', 'sourceforge']\n"
     ]
    }
   ],
   "source": [
    "stopwords2 = []\n",
    "ham_list = hamwords.keys()\n",
    "spam_list = spamwords.keys()\n",
    "\n",
    "for key in list(hamwords):\n",
    "    if key in list(spamwords):\n",
    "        if hamwords[key] > 500 and spamwords[key] > 500:\n",
    "            stopwords2.append(key)            \n",
    "print(stopwords2)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB_model:\n",
    "    \n",
    "    def __init__(self,msg):\n",
    "        self.spam_prob_dict ={}\n",
    "        self.ham_prob_dict = {}\n",
    "        self.prob_spam = 0\n",
    "        self.prob_ham = 0\n",
    "        self.tot_ham_words = 0\n",
    "        self.tot_spam_words = 0        \n",
    "        print(msg)                    \n",
    "        \n",
    "    def getData(self):\n",
    "        vocab = []\n",
    "        hamwords = {}\n",
    "        hamdoc_count = 0\n",
    "        hamfiles = [file for file in glob.glob(\"./train/*ham*.txt\")]\n",
    "        self.stopwords = stopwords\n",
    "\n",
    "        for file in hamfiles:\n",
    "            hamdoc_count  = hamdoc_count+1\n",
    "            doc = open(file, 'r').read().lower()\n",
    "            doc = re.sub('[a-z]*@*.com', '', doc)\n",
    "            doc = re.sub('<*[a-z]*>', '', doc)\n",
    "            words = [word for word in re.split('[^a-zA-Z]',doc)]\n",
    "            for word in words:\n",
    "                if word != '':\n",
    "                    try:\n",
    "                        hamwords[word] += 1\n",
    "                    except KeyError:\n",
    "                        hamwords[word] = 1\n",
    "\n",
    "        spamdoc_count = 0\n",
    "        spamwords = {}\n",
    "        spamfiles = [file for file in glob.glob(\"./train/*spam*.txt\")]\n",
    "        for file in spamfiles:\n",
    "            spamdoc_count = spamdoc_count+1\n",
    "            doc = open(file, 'r').read().lower()\n",
    "            words = [word for word in re.split('[^a-zA-Z]',doc)]\n",
    "            for word in words:\n",
    "                if word != '':\n",
    "                    try:\n",
    "                        spamwords[word] += 1\n",
    "                    except KeyError:\n",
    "                        spamwords[word] = 1\n",
    "        return hamwords, spamwords, hamdoc_count, spamdoc_count\n",
    "\n",
    "    def train(self, hm_dict, sp_dict, hm_prob, sp_prob):\n",
    "        vocab_set = []\n",
    "        self.prob_spam = sp_prob\n",
    "        self.prob_ham = hm_prob\n",
    "        for key,value in hm_dict.items():\n",
    "            self.tot_ham_words += value\n",
    "            vocab_set.append(key)\n",
    "        vocab_set = set(vocab_set)\n",
    "    \n",
    "        print(len(vocab_set))\n",
    "        for key,value in spamwords.items():\n",
    "            self.tot_spam_words += value\n",
    "            vocab_set.add(key)\n",
    "        print(len(vocab_set))\n",
    "        self.vocab = list(vocab_set)\n",
    "        print(len(self.vocab))\n",
    "        file = open(\"./model.txt\", 'w+')\n",
    "    \n",
    "        index = 1\n",
    "        for word in sorted(self.vocab):\n",
    "            try:\n",
    "                hm_dict[word] += 0\n",
    "            except KeyError:\n",
    "                hm_dict[word] = 0\n",
    "                \n",
    "            try:\n",
    "                sp_dict[word] += 0\n",
    "            except KeyError:\n",
    "                sp_dict[word] = 0\n",
    "                \n",
    "            prob_word_ham = (hm_dict[word]+0.5)/(self.tot_ham_words+len(self.vocab))\n",
    "            self.ham_prob_dict[word] = prob_word_ham\n",
    "            prob_word_spam = (sp_dict[word]+0.5)/(self.tot_spam_words+len(self.vocab))\n",
    "            self.spam_prob_dict[word] = prob_word_spam\n",
    "           # print(\"%d  %s  %d  %f  %d  %f\"%(index, word, hm_dict[word], prob_word_ham, sp_dict[word], prob_word_spam))\n",
    "            file.write(\"%d  %s  %d  %f  %d  %f\\n\"%(index, word, hm_dict[word], prob_word_ham, sp_dict[word], prob_word_spam))\n",
    "            index +=1\n",
    "            \n",
    "        file.close()\n",
    "        \n",
    "    def test(self, words):\n",
    "        score_ham = math.log10(self.prob_ham)\n",
    "        score_spam = math.log10(self.prob_spam)\n",
    "        for word in words:\n",
    "            if word != '':\n",
    "                try:\n",
    "                    self.ham_prob_dict[word] += 0\n",
    "                except KeyError:\n",
    "                    self.ham_prob_dict[word] = 0.5/(self.tot_ham_words+len(self.vocab))\n",
    "                    self.spam_prob_dict[word] = 0.5/(self.tot_spam_words+len(self.vocab))\n",
    "                \n",
    "                score_ham = score_ham + math.log10(self.ham_prob_dict[word])\n",
    "                score_spam = score_spam + math.log10(self.spam_prob_dict[word])              \n",
    "            \n",
    "        if score_ham > score_spam:\n",
    "            return(\"ham\",score_ham,score_spam)\n",
    "        else:\n",
    "            return(\"spam\",score_ham,score_spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating object\n",
      "19768\n",
      "59719\n",
      "59719\n"
     ]
    }
   ],
   "source": [
    "model = NB_model(\"creating object\")\n",
    "#stopwords = model.getStopwords()\n",
    "hamwords, spamwords, hamdoc_count, spamdoc_count = model.getData()           \n",
    "prob_ham = (hamdoc_count/(hamdoc_count+spamdoc_count))\n",
    "prob_spam = (spamdoc_count/(hamdoc_count+spamdoc_count))\n",
    "model.train(hamwords,spamwords,prob_ham,prob_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "y_act = []\n",
    "y_pred = []\n",
    "res_file = open(\"./result.txt\", 'w+')\n",
    "ham_test_files = [file for file in glob.glob(\"./test/*ham*.txt\")]\n",
    "\n",
    "for file in ham_test_files:\n",
    "    doc = open(file, 'r').read().lower()\n",
    "    words = [word for word in re.split('[^a-zA-Z]',doc)]\n",
    "    (result,h_score,s_score) = model.test(words)\n",
    "    y_act.append(0)\n",
    "    if result == \"ham\":\n",
    "        output = 'right'\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        output = 'wrong'\n",
    "        y_pred.append(1)\n",
    "    #print(\"%d  %s  %s  %f  %f  %s  %s\"%(index, file, result, h_score, s_score, \"ham\", output))\n",
    "    res_file.write(\"%d  %s  %s  %f  %f  %s  %s \\n\"%(index, file, result, h_score, s_score, \"ham\", output))\n",
    "    index += 1\n",
    "    \n",
    "spam_test_files = [file for file in glob.glob(\"./test/*spam*.txt\")]\n",
    "\n",
    "for file in spam_test_files:\n",
    "    doc = open(file, 'r', encoding='cp437').read().lower()\n",
    "    words = [word for word in re.split('[^a-zA-Z]',doc)]\n",
    "    (result,h_score,s_score) = model.test(words)\n",
    "    y_act.append(1)\n",
    "    if result == \"ham\":\n",
    "        output = 'wrong'\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        output = 'right'\n",
    "        y_pred.append(1)\n",
    "    #print(\"%d  %s  %s  %f  %f  %s  %s\"%(index, file, result, h_score, s_score, \"spam\", output))\n",
    "    res_file.write(\"%d  %s  %s  %f  %f  %s  %s \\n\"%(index, file, result, h_score, s_score, \"spam\", output))\n",
    "    index += 1\n",
    "    \n",
    "res_file.close()\n",
    "\n",
    "#resultFn(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultFn(true_pos, true_neg, false_pos, false_neg):\n",
    "    print(\"-------------------------------------------Evaluation--------------------------------------------\")\n",
    "    print(\"true_pos : \"+ str(true_pos) +\"\\ntrue_neg : \"+str(true_neg)+\"\\nfalse_pos : \"+ str(false_pos) +\"\\nfalse_neg : \"+ str(false_neg) +\"\\n\")\n",
    "    precision = true_pos/(true_pos + false_pos)\n",
    "    recall = true_pos/(true_pos + false_neg)\n",
    "    f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "    accuracy = (true_pos)/(true_pos + false_neg)\n",
    "    print(\"Precision : \"+str(precision*100) + \"\\nRecall : \"+str(recall*100)+\"\\nF1-score : \"+str(f1*100)+\"\\nAccuracy : \"+str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------Evaluation--------------------------------------------\n",
      "true_pos : 385\n",
      "true_neg : 361\n",
      "false_pos : 39\n",
      "false_neg : 15\n",
      "\n",
      "Precision : 90.80188679245283\n",
      "Recall : 96.25\n",
      "F1-score : 93.44660194174757\n",
      "Accuracy : 96.25\n"
     ]
    }
   ],
   "source": [
    "# positive = ham and negative = spam\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range(len(y_act)):\n",
    "    if y_act[i] == 1 and y_pred[i] == 1:\n",
    "        tp += 1\n",
    "    elif y_act[i] == 1 and y_pred[i] == 0:\n",
    "        fn += 1\n",
    "    elif y_act[i] == 0 and y_pred[i] == 1:\n",
    "        fp += 1\n",
    "    else:\n",
    "        tn += 1\n",
    "resultFn(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------Evaluation--------------------------------------------\n",
      "true_pos : 361\n",
      "true_neg : 385\n",
      "false_pos : 15\n",
      "false_neg : 39\n",
      "\n",
      "Precision : 96.01063829787235\n",
      "Recall : 90.25\n",
      "F1-score : 93.04123711340206\n",
      "Accuracy : 90.25\n"
     ]
    }
   ],
   "source": [
    "# positive = spam and negative = ham\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range(len(y_act)):\n",
    "    if y_act[i] == 0 and y_pred[i] == 0:\n",
    "        tp += 1\n",
    "    elif y_act[i] == 0 and y_pred[i] == 1:\n",
    "        fn += 1\n",
    "    elif y_act[i] == 1 and y_pred[i] == 0:\n",
    "        fp += 1\n",
    "    else:\n",
    "        tn += 1\n",
    "resultFn(tp, tn, fp, fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
